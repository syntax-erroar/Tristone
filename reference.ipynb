{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced SEC Financial Model Generator for Google Colab\n",
    "# Addresses accuracy issues with advanced XBRL processing, semantic matching, and validation\n",
    "# FIXED: Added missing _aggregate_category_values method and other improvements\n",
    "\n",
    "# Install required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install all required packages for Colab\"\"\"\n",
    "    packages = [\n",
    "        'arelle',\n",
    "        'sentence-transformers',\n",
    "        'lxml',\n",
    "        'sec-edgar-downloader',\n",
    "        'edgar-tool',\n",
    "        'alpha-vantage',\n",
    "        'scikit-learn',\n",
    "        'transformers',\n",
    "        'torch',\n",
    "        'yfinance',\n",
    "        'openpyxl',\n",
    "        'pandas',\n",
    "        'numpy',\n",
    "        'requests',\n",
    "        'python-dateutil'\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "            print(f\"✓ Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"✗ Failed to install {package}\")\n",
    "\n",
    "# Uncomment the next line for first run in Colab\n",
    "# install_packages()\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
    "import os\n",
    "from typing import Dict, List, Optional, Any, Tuple, Set, Union\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from dateutil.parser import parse as parse_date\n",
    "import itertools\n",
    "from functools import lru_cache\n",
    "import yfinance as yf\n",
    "from difflib import SequenceMatcher\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree, html\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "# Advanced libraries for enhanced processing\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from scipy import stats\n",
    "    import torch\n",
    "    ADVANCED_LIBS_AVAILABLE = True\n",
    "    print(\"✓ Advanced libraries loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Advanced libraries not available: {e}\")\n",
    "    ADVANCED_LIBS_AVAILABLE = False\n",
    "\n",
    "class EnhancedSECFinancialModelGenerator:\n",
    "    def __init__(self, company_name: str, ticker: str, cik: str, user_agent_email: str,\n",
    "                 fiscal_year_end: str = \"0630\"):\n",
    "        \"\"\"\n",
    "        Enhanced SEC Financial Model Generator with semantic matching and validation\n",
    "        \"\"\"\n",
    "        self.company_name = company_name\n",
    "        self.ticker = ticker\n",
    "        self.cik = cik.zfill(10)\n",
    "        self.fiscal_year_end = fiscal_year_end\n",
    "        self.user_agent_email = user_agent_email\n",
    "\n",
    "        self.headers = {\n",
    "            'User-Agent': f'{company_name} Financial Analysis Tool ({user_agent_email})'\n",
    "        }\n",
    "        self.base_url = \"https://data.sec.gov/api/xbrl\"\n",
    "\n",
    "        # Enhanced data storage\n",
    "        self.facts_data = {}\n",
    "        self.standardized_categories = {}\n",
    "        self.market_data = {}\n",
    "        self.raw_metrics = {}\n",
    "        self.xbrl_contexts = {}\n",
    "        self.filing_metadata = {}\n",
    "        self.data_quality_scores = {}\n",
    "        self.validation_results = {}\n",
    "\n",
    "        # Initialize semantic model if available\n",
    "        self.semantic_model = None\n",
    "        if ADVANCED_LIBS_AVAILABLE:\n",
    "            try:\n",
    "                self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "                print(\"✓ Semantic model loaded for intelligent concept matching\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Could not load semantic model: {e}\")\n",
    "\n",
    "        # Enhanced metric patterns with semantic concepts\n",
    "        self.financial_concepts = self._initialize_enhanced_concepts()\n",
    "        self.industry_adjustments = self._load_industry_mappings()\n",
    "\n",
    "    def _initialize_enhanced_concepts(self) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Initialize enhanced financial concepts with semantic descriptions\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'revenue': {\n",
    "                'display_name': 'Total Revenue',\n",
    "                'semantic_description': 'total revenue from operations sales income',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'RevenueFromContractWithCustomerExcludingAssessedTax',\n",
    "                    'RevenueFromContractWithCustomer',\n",
    "                    'Revenues', 'SalesRevenueNet', 'RevenueNet',\n",
    "                    'TotalRevenue', 'Revenue', 'SalesRevenue'\n",
    "                ],\n",
    "                'required_characteristics': ['revenue', 'sales', 'income'],\n",
    "                'exclusion_terms': ['segment', 'geographic', 'cost', 'expense', 'deferred'],\n",
    "                'statement_section': 'income_statement',\n",
    "                'data_type': 'flow',\n",
    "                'priority': 100\n",
    "            },\n",
    "            'cost_of_revenue': {\n",
    "                'display_name': 'Cost of Revenue',\n",
    "                'semantic_description': 'direct costs of goods sold services provided cost of sales',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'CostOfGoodsAndServicesSold', 'CostOfRevenue', 'CostOfSales',\n",
    "                    'CostOfGoodsAndServicesSoldExcludingDepreciationDepletionAndAmortization'\n",
    "                ],\n",
    "                'required_characteristics': ['cost'],\n",
    "                'exclusion_terms': ['research', 'development', 'marketing', 'administrative'],\n",
    "                'statement_section': 'income_statement',\n",
    "                'data_type': 'flow',\n",
    "                'priority': 85\n",
    "            },\n",
    "            'operating_income': {\n",
    "                'display_name': 'Operating Income',\n",
    "                'semantic_description': 'income from operations operating profit earnings',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'OperatingIncomeLoss', 'IncomeLossFromContinuingOperations',\n",
    "                    'OperatingIncome', 'OperatingProfit'\n",
    "                ],\n",
    "                'required_characteristics': ['operating'],\n",
    "                'exclusion_terms': ['expense', 'cost', 'nonoperating', 'before', 'tax'],\n",
    "                'statement_section': 'income_statement',\n",
    "                'data_type': 'flow',\n",
    "                'priority': 95\n",
    "            },\n",
    "            'net_income': {\n",
    "                'display_name': 'Net Income',\n",
    "                'semantic_description': 'net earnings profit after tax bottom line',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'NetIncomeLoss', 'ProfitLoss', 'NetIncome',\n",
    "                    'NetIncomeLossAvailableToCommonStockholdersBasic'\n",
    "                ],\n",
    "                'required_characteristics': ['net'],\n",
    "                'exclusion_terms': ['operating', 'gross', 'comprehensive', 'before'],\n",
    "                'statement_section': 'income_statement',\n",
    "                'data_type': 'flow',\n",
    "                'priority': 95\n",
    "            },\n",
    "            'cash_flow_operations': {\n",
    "                'display_name': 'Operating Cash Flow',\n",
    "                'semantic_description': 'cash flow from operating activities operations',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'NetCashProvidedByUsedInOperatingActivities',\n",
    "                    'CashProvidedByUsedInOperatingActivities'\n",
    "                ],\n",
    "                'required_characteristics': ['cash', 'operating'],\n",
    "                'exclusion_terms': ['investing', 'financing'],\n",
    "                'statement_section': 'cash_flow',\n",
    "                'data_type': 'flow',\n",
    "                'priority': 90\n",
    "            },\n",
    "            'cash_equivalents': {\n",
    "                'display_name': 'Cash and Cash Equivalents',\n",
    "                'semantic_description': 'cash short term investments liquid assets',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'CashAndCashEquivalentsAtCarryingValue',\n",
    "                    'CashCashEquivalentsAndShortTermInvestments',\n",
    "                    'Cash', 'CashAndEquivalents'\n",
    "                ],\n",
    "                'required_characteristics': ['cash'],\n",
    "                'exclusion_terms': ['restricted'],\n",
    "                'statement_section': 'balance_sheet',\n",
    "                'data_type': 'stock',\n",
    "                'priority': 85\n",
    "            },\n",
    "            'total_assets': {\n",
    "                'display_name': 'Total Assets',\n",
    "                'semantic_description': 'total assets balance sheet resources',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'Assets', 'AssetsCurrent', 'AssetsNoncurrent'\n",
    "                ],\n",
    "                'required_characteristics': ['assets', 'total'],\n",
    "                'exclusion_terms': ['liabilities', 'equity', 'net'],\n",
    "                'statement_section': 'balance_sheet',\n",
    "                'data_type': 'stock',\n",
    "                'priority': 90\n",
    "            },\n",
    "            'total_liabilities': {\n",
    "                'display_name': 'Total Liabilities',\n",
    "                'semantic_description': 'total liabilities debt obligations',\n",
    "                'common_xbrl_concepts': [\n",
    "                    'Liabilities', 'LiabilitiesCurrent', 'LiabilitiesNoncurrent'\n",
    "                ],\n",
    "                'required_characteristics': ['liabilities'],\n",
    "                'exclusion_terms': ['assets', 'equity'],\n",
    "                'statement_section': 'balance_sheet',\n",
    "                'data_type': 'stock',\n",
    "                'priority': 85\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _load_industry_mappings(self) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Load industry-specific XBRL concept mappings\n",
    "        \"\"\"\n",
    "        # This would typically load from a comprehensive database\n",
    "        # For now, we'll include basic mappings for common industries\n",
    "        return {\n",
    "            'technology': {\n",
    "                'segment_revenue_patterns': ['ProductivityAndBusinessProcesses', 'IntelligentCloud'],\n",
    "                'specific_costs': ['ResearchAndDevelopment'],\n",
    "                'common_adjustments': ['ShareBasedCompensation']\n",
    "            },\n",
    "            'financial': {\n",
    "                'segment_revenue_patterns': ['InterestIncome', 'NoninterestIncome'],\n",
    "                'specific_costs': ['ProvisionForLoanLosses'],\n",
    "                'common_adjustments': ['CreditLosses']\n",
    "            },\n",
    "            'manufacturing': {\n",
    "                'segment_revenue_patterns': ['ProductSales', 'ServiceRevenue'],\n",
    "                'specific_costs': ['RawMaterials', 'Manufacturing'],\n",
    "                'common_adjustments': ['InventoryWritedown']\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def fetch_sec_data(self) -> bool:\n",
    "        \"\"\"\n",
    "        Enhanced SEC data fetching with metadata collection\n",
    "        \"\"\"\n",
    "        print(f\"Fetching {self.company_name} financial data from SEC EDGAR...\")\n",
    "\n",
    "        try:\n",
    "            # Fetch company facts\n",
    "            url = f\"{self.base_url}/companyfacts/CIK{self.cik}.json\"\n",
    "            response = requests.get(url, headers=self.headers, timeout=60)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                self.facts_data = response.json()\n",
    "                print(f\"✓ Retrieved {self.company_name} SEC data\")\n",
    "\n",
    "                # Extract filing metadata\n",
    "                self._extract_filing_metadata()\n",
    "\n",
    "                # Debug info\n",
    "                if 'facts' in self.facts_data:\n",
    "                    total_metrics = sum(len(metrics) for metrics in self.facts_data['facts'].values())\n",
    "                    print(f\"  Found {total_metrics} total metrics across taxonomies\")\n",
    "\n",
    "                    # Show taxonomy breakdown\n",
    "                    for taxonomy, metrics in self.facts_data['facts'].items():\n",
    "                        print(f\"  {taxonomy}: {len(metrics)} metrics\")\n",
    "\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"✗ Failed to fetch SEC data: HTTP {response.status_code}\")\n",
    "                return False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error fetching SEC data: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _extract_filing_metadata(self):\n",
    "        \"\"\"\n",
    "        Extract metadata about filings for validation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if 'entityName' in self.facts_data:\n",
    "                self.filing_metadata['entity_name'] = self.facts_data['entityName']\n",
    "\n",
    "            if 'cik' in self.facts_data:\n",
    "                self.filing_metadata['cik'] = self.facts_data['cik']\n",
    "\n",
    "            # Extract filing periods and forms\n",
    "            filing_periods = set()\n",
    "            forms = set()\n",
    "\n",
    "            for taxonomy, metrics in self.facts_data.get('facts', {}).items():\n",
    "                for metric_name, metric_data in metrics.items():\n",
    "                    units = metric_data.get('units', {})\n",
    "                    for unit_type, entries in units.items():\n",
    "                        for entry in entries:\n",
    "                            if entry.get('form'):\n",
    "                                forms.add(entry['form'])\n",
    "                            if entry.get('fy'):\n",
    "                                filing_periods.add(entry['fy'])\n",
    "\n",
    "            self.filing_metadata['periods'] = sorted(list(filing_periods))\n",
    "            self.filing_metadata['forms'] = list(forms)\n",
    "\n",
    "            print(f\"  Filing periods: {len(filing_periods)} years\")\n",
    "            print(f\"  Form types: {', '.join(sorted(forms))}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Could not extract filing metadata: {e}\")\n",
    "\n",
    "    def fetch_market_data(self):\n",
    "        \"\"\"\n",
    "        Enhanced market data fetching with validation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Fetching market data for {self.ticker}...\")\n",
    "            stock = yf.Ticker(self.ticker)\n",
    "            info = stock.info\n",
    "            hist = stock.history(period=\"1y\")\n",
    "\n",
    "            self.market_data = {\n",
    "                'market_cap': info.get('marketCap', 0) / 1000000,  # Convert to millions\n",
    "                'shares_outstanding': info.get('sharesOutstanding', 0) / 1000000,\n",
    "                'current_price': info.get('currentPrice', 0),\n",
    "                'enterprise_value': info.get('enterpriseValue', 0) / 1000000 if info.get('enterpriseValue') else 0,\n",
    "                'beta': info.get('beta', 1.0),\n",
    "                'sector': info.get('sector', 'Unknown'),\n",
    "                'industry': info.get('industry', 'Unknown'),\n",
    "                '52_week_high': info.get('fiftyTwoWeekHigh', 0),\n",
    "                '52_week_low': info.get('fiftyTwoWeekLow', 0),\n",
    "                'avg_volume': info.get('averageVolume', 0),\n",
    "                'price_volatility': hist['Close'].pct_change().std() * np.sqrt(252) if not hist.empty else 0\n",
    "            }\n",
    "\n",
    "            print(f\"  Market cap: ${self.market_data['market_cap']:,.0f}M\")\n",
    "            print(f\"  Sector: {self.market_data['sector']}\")\n",
    "            print(f\"  Industry: {self.market_data['industry']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Could not fetch market data: {e}\")\n",
    "            self.market_data = {\n",
    "                'market_cap': 0, 'shares_outstanding': 0, 'current_price': 0,\n",
    "                'enterprise_value': 0, 'beta': 1.0, 'sector': 'Unknown',\n",
    "                'industry': 'Unknown', '52_week_high': 0, '52_week_low': 0,\n",
    "                'avg_volume': 0, 'price_volatility': 0\n",
    "            }\n",
    "\n",
    "    def find_and_classify_metrics(self):\n",
    "        \"\"\"\n",
    "        Enhanced metric classification using semantic matching and validation\n",
    "        \"\"\"\n",
    "        if not self.facts_data or 'facts' not in self.facts_data:\n",
    "            print(\"✗ No facts data available\")\n",
    "            return\n",
    "\n",
    "        print(\"Finding and classifying financial metrics using enhanced methods...\")\n",
    "\n",
    "        # Store all raw metrics with context information\n",
    "        self._extract_raw_metrics_with_context()\n",
    "\n",
    "        # Multi-pass classification with validation\n",
    "        self._semantic_classification()\n",
    "        self._pattern_based_fallback()\n",
    "        self._context_validation()\n",
    "        self._cross_validation()\n",
    "\n",
    "        print(f\"\\n✓ Classification complete: {len(self.standardized_categories)} categories matched\")\n",
    "\n",
    "        # Generate quality scores\n",
    "        self._calculate_data_quality_scores()\n",
    "\n",
    "    def _extract_raw_metrics_with_context(self):\n",
    "        \"\"\"\n",
    "        Extract raw metrics with full context information for validation\n",
    "        \"\"\"\n",
    "        print(\"  Extracting raw metrics with context...\")\n",
    "\n",
    "        for taxonomy in self.facts_data['facts']:\n",
    "            for metric_name, metric_data in self.facts_data['facts'][taxonomy].items():\n",
    "\n",
    "                # Extract context information from units\n",
    "                contexts = []\n",
    "                for unit_type, entries in metric_data.get('units', {}).items():\n",
    "                    for entry in entries:\n",
    "                        context = {\n",
    "                            'start': entry.get('start'),\n",
    "                            'end': entry.get('end'),\n",
    "                            'val': entry.get('val'),\n",
    "                            'accn': entry.get('accn'),\n",
    "                            'fy': entry.get('fy'),\n",
    "                            'fp': entry.get('fp'),\n",
    "                            'form': entry.get('form'),\n",
    "                            'filed': entry.get('filed'),\n",
    "                            'unit_type': unit_type\n",
    "                        }\n",
    "                        contexts.append(context)\n",
    "\n",
    "                self.raw_metrics[f\"{taxonomy}:{metric_name}\"] = {\n",
    "                    'name': metric_name,\n",
    "                    'description': metric_data.get('description', ''),\n",
    "                    'label': metric_data.get('label', ''),\n",
    "                    'data': metric_data,\n",
    "                    'taxonomy': taxonomy,\n",
    "                    'contexts': contexts\n",
    "                }\n",
    "\n",
    "        print(f\"  Extracted {len(self.raw_metrics)} raw metrics with contexts\")\n",
    "\n",
    "    def _semantic_classification(self):\n",
    "        \"\"\"\n",
    "        Use semantic similarity to match financial concepts\n",
    "        \"\"\"\n",
    "        if not self.semantic_model:\n",
    "            print(\"  Skipping semantic classification (model not available)\")\n",
    "            return\n",
    "\n",
    "        print(\"  Running semantic classification...\")\n",
    "\n",
    "        # Create embeddings for financial concepts\n",
    "        concept_texts = []\n",
    "        concept_keys = []\n",
    "\n",
    "        for concept_key, concept_info in self.financial_concepts.items():\n",
    "            text = f\"{concept_info['display_name']} {concept_info['semantic_description']}\"\n",
    "            concept_texts.append(text)\n",
    "            concept_keys.append(concept_key)\n",
    "\n",
    "        concept_embeddings = self.semantic_model.encode(concept_texts)\n",
    "\n",
    "        # Create embeddings for raw metrics\n",
    "        metric_texts = []\n",
    "        metric_keys = []\n",
    "\n",
    "        for metric_key, metric_info in self.raw_metrics.items():\n",
    "            text = f\"{metric_info['name']} {metric_info['description']} {metric_info['label']}\"\n",
    "            metric_texts.append(text)\n",
    "            metric_keys.append(metric_key)\n",
    "\n",
    "        metric_embeddings = self.semantic_model.encode(metric_texts)\n",
    "\n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(metric_embeddings, concept_embeddings)\n",
    "\n",
    "        # Find best matches\n",
    "        semantic_matches = 0\n",
    "        for i, metric_key in enumerate(metric_keys):\n",
    "            best_concept_idx = np.argmax(similarities[i])\n",
    "            best_similarity = similarities[i][best_concept_idx]\n",
    "\n",
    "            if best_similarity > 0.7:  # High confidence threshold\n",
    "                concept_key = concept_keys[best_concept_idx]\n",
    "                metric_info = self.raw_metrics[metric_key]\n",
    "\n",
    "                print(f\"    SEMANTIC: {metric_info['name']} -> {concept_key} ({best_similarity:.3f})\")\n",
    "\n",
    "                self._add_metric_to_category(\n",
    "                    concept_key,\n",
    "                    metric_info['name'],\n",
    "                    metric_info['data'],\n",
    "                    metric_info['taxonomy'],\n",
    "                    best_similarity,\n",
    "                    'semantic'\n",
    "                )\n",
    "                semantic_matches += 1\n",
    "\n",
    "        print(f\"  Semantic classification: {semantic_matches} matches found\")\n",
    "\n",
    "    def _pattern_based_fallback(self):\n",
    "        \"\"\"\n",
    "        Pattern-based matching for concepts not found semantically\n",
    "        \"\"\"\n",
    "        print(\"  Running pattern-based fallback...\")\n",
    "\n",
    "        unmatched_concepts = [\n",
    "            concept for concept in self.financial_concepts.keys()\n",
    "            if concept not in self.standardized_categories\n",
    "        ]\n",
    "\n",
    "        pattern_matches = 0\n",
    "\n",
    "        for concept_key in unmatched_concepts:\n",
    "            concept_info = self.financial_concepts[concept_key]\n",
    "            best_matches = []\n",
    "\n",
    "            # Check exact matches first\n",
    "            for metric_key, metric_info in self.raw_metrics.items():\n",
    "                metric_name = metric_info['name']\n",
    "\n",
    "                if metric_name in concept_info.get('common_xbrl_concepts', []):\n",
    "                    best_matches.append((metric_key, metric_info, 1.0))\n",
    "                    continue\n",
    "\n",
    "                # Pattern matching\n",
    "                score = self._calculate_pattern_score(metric_info, concept_info)\n",
    "                if score > 0.6:\n",
    "                    best_matches.append((metric_key, metric_info, score))\n",
    "\n",
    "            if best_matches:\n",
    "                best_matches.sort(key=lambda x: x[2], reverse=True)\n",
    "                metric_key, metric_info, score = best_matches[0]\n",
    "\n",
    "                print(f\"    PATTERN: {metric_info['name']} -> {concept_key} ({score:.3f})\")\n",
    "\n",
    "                self._add_metric_to_category(\n",
    "                    concept_key,\n",
    "                    metric_info['name'],\n",
    "                    metric_info['data'],\n",
    "                    metric_info['taxonomy'],\n",
    "                    score,\n",
    "                    'pattern'\n",
    "                )\n",
    "                pattern_matches += 1\n",
    "\n",
    "        print(f\"  Pattern classification: {pattern_matches} matches found\")\n",
    "\n",
    "    def _calculate_pattern_score(self, metric_info: Dict, concept_info: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Enhanced pattern scoring with multiple factors\n",
    "        \"\"\"\n",
    "        text = f\"{metric_info['name']} {metric_info['description']}\".lower()\n",
    "        score = 0.0\n",
    "\n",
    "        # Required characteristics (must have all)\n",
    "        required = concept_info.get('required_characteristics', [])\n",
    "        if required:\n",
    "            matches = sum(1 for req in required if req.lower() in text)\n",
    "            if matches == len(required):\n",
    "                score += 0.4\n",
    "            elif matches > 0:\n",
    "                score += 0.2 * (matches / len(required))\n",
    "            else:\n",
    "                return 0.0  # Fail if missing required characteristics\n",
    "\n",
    "        # Exclusion terms (must have none)\n",
    "        exclusions = concept_info.get('exclusion_terms', [])\n",
    "        for exclusion in exclusions:\n",
    "            if exclusion.lower() in text:\n",
    "                return 0.0  # Immediate disqualification\n",
    "\n",
    "        # Common XBRL concepts (bonus points)\n",
    "        common_concepts = concept_info.get('common_xbrl_concepts', [])\n",
    "        for concept in common_concepts:\n",
    "            similarity = SequenceMatcher(None, metric_info['name'], concept).ratio()\n",
    "            if similarity > 0.8:\n",
    "                score += 0.3\n",
    "            elif similarity > 0.6:\n",
    "                score += 0.2\n",
    "\n",
    "        # Statement section alignment\n",
    "        if concept_info.get('statement_section') == 'balance_sheet':\n",
    "            if any(term in text for term in ['balance', 'sheet', 'asset', 'liability', 'equity']):\n",
    "                score += 0.1\n",
    "        elif concept_info.get('statement_section') == 'income_statement':\n",
    "            if any(term in text for term in ['income', 'revenue', 'expense', 'profit', 'loss']):\n",
    "                score += 0.1\n",
    "        elif concept_info.get('statement_section') == 'cash_flow':\n",
    "            if any(term in text for term in ['cash', 'flow', 'activities']):\n",
    "                score += 0.1\n",
    "\n",
    "        return min(score, 1.0)\n",
    "\n",
    "    def _context_validation(self):\n",
    "        \"\"\"\n",
    "        Validate contexts to ensure data consistency\n",
    "        \"\"\"\n",
    "        print(\"  Validating contexts...\")\n",
    "\n",
    "        for category_key, category_data in self.standardized_categories.items():\n",
    "            if not category_data.get('metrics'):\n",
    "                continue\n",
    "\n",
    "            # Validate time periods\n",
    "            all_periods = set()\n",
    "            for metric_info in category_data['metrics']:\n",
    "                metric_key = f\"{metric_info['taxonomy']}:{metric_info['name']}\"\n",
    "                if metric_key in self.raw_metrics:\n",
    "                    contexts = self.raw_metrics[metric_key]['contexts']\n",
    "                    for context in contexts:\n",
    "                        if context.get('fy'):\n",
    "                            all_periods.add(context['fy'])\n",
    "\n",
    "            # Flag periods with insufficient data\n",
    "            insufficient_periods = []\n",
    "            for period in all_periods:\n",
    "                period_data_count = 0\n",
    "                for metric_info in category_data['metrics']:\n",
    "                    metric_key = f\"{metric_info['taxonomy']}:{metric_info['name']}\"\n",
    "                    if metric_key in self.raw_metrics:\n",
    "                        contexts = self.raw_metrics[metric_key]['contexts']\n",
    "                        period_contexts = [c for c in contexts if c.get('fy') == period]\n",
    "                        period_data_count += len(period_contexts)\n",
    "\n",
    "                if period_data_count < len(category_data['metrics']):\n",
    "                    insufficient_periods.append(period)\n",
    "\n",
    "            if insufficient_periods:\n",
    "                print(f\"    ⚠ {category_key}: Insufficient data for periods {insufficient_periods}\")\n",
    "\n",
    "    def _cross_validation(self):\n",
    "        \"\"\"\n",
    "        Cross-validate financial relationships\n",
    "        \"\"\"\n",
    "        print(\"  Running cross-validation...\")\n",
    "\n",
    "        validation_rules = [\n",
    "            ('revenue', 'cost_of_revenue', 'revenue >= cost_of_revenue'),\n",
    "            ('operating_income', 'net_income', 'abs(operating_income) >= abs(net_income) * 0.5'),\n",
    "            ('total_assets', 'cash_equivalents', 'total_assets >= cash_equivalents'),\n",
    "        ]\n",
    "\n",
    "        validation_failures = 0\n",
    "\n",
    "        for rule in validation_rules:\n",
    "            concept1, concept2, rule_desc = rule\n",
    "\n",
    "            if concept1 in self.standardized_categories and concept2 in self.standardized_categories:\n",
    "                # Get recent data for validation\n",
    "                data1 = self.standardized_categories[concept1].get('annual_data', {})\n",
    "                data2 = self.standardized_categories[concept2].get('annual_data', {})\n",
    "\n",
    "                common_years = set(data1.keys()) & set(data2.keys())\n",
    "\n",
    "                for year in common_years:\n",
    "                    val1 = self._aggregate_category_values(self.standardized_categories[concept1], year)\n",
    "                    val2 = self._aggregate_category_values(self.standardized_categories[concept2], year)\n",
    "\n",
    "                    if val1 is not None and val2 is not None:\n",
    "                        # Apply validation rule\n",
    "                        if concept1 == 'revenue' and concept2 == 'cost_of_revenue':\n",
    "                            if val1 < val2:\n",
    "                                print(f\"    ⚠ {year}: Revenue ({val1:.1f}) < Cost of Revenue ({val2:.1f})\")\n",
    "                                validation_failures += 1\n",
    "\n",
    "                        elif concept1 == 'operating_income' and concept2 == 'net_income':\n",
    "                            if abs(val1) < abs(val2) * 0.5:\n",
    "                                print(f\"    ⚠ {year}: Operating Income relationship anomaly\")\n",
    "                                validation_failures += 1\n",
    "\n",
    "        if validation_failures == 0:\n",
    "            print(\"  ✓ Cross-validation passed\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Cross-validation: {validation_failures} potential issues found\")\n",
    "\n",
    "    def _aggregate_category_values(self, category_data: Dict, year: int) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        FIXED: Added missing method to aggregate values for a category in a specific year\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get all annual values for the year\n",
    "            annual_values = category_data.get('annual_data', {}).get(year, [])\n",
    "\n",
    "            if not annual_values:\n",
    "                return None\n",
    "\n",
    "            # Clean and aggregate values\n",
    "            clean_values = [v for v in annual_values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
    "\n",
    "            if not clean_values:\n",
    "                return None\n",
    "\n",
    "            # Use median to handle outliers\n",
    "            return np.median(clean_values)\n",
    "\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _calculate_data_quality_scores(self):\n",
    "        \"\"\"\n",
    "        Calculate quality scores for each category\n",
    "        \"\"\"\n",
    "        print(\"  Calculating data quality scores...\")\n",
    "\n",
    "        for category_key, category_data in self.standardized_categories.items():\n",
    "            score_factors = {\n",
    "                'completeness': 0,\n",
    "                'consistency': 0,\n",
    "                'accuracy': 0,\n",
    "                'timeliness': 0\n",
    "            }\n",
    "\n",
    "            # Completeness: How many expected periods have data\n",
    "            expected_periods = range(2018, 2025)\n",
    "            available_periods = list(category_data.get('annual_data', {}).keys())\n",
    "            if expected_periods:\n",
    "                score_factors['completeness'] = len(available_periods) / len(expected_periods)\n",
    "\n",
    "            # Consistency: How consistent are values across metrics\n",
    "            if len(category_data.get('metrics', [])) > 1:\n",
    "                # Check variance across different metrics for same concept\n",
    "                consistency_scores = []\n",
    "                for year in available_periods:\n",
    "                    values = category_data['annual_data'].get(year, [])\n",
    "                    if len(values) > 1:\n",
    "                        cv = np.std(values) / np.mean(values) if np.mean(values) != 0 else 1\n",
    "                        consistency_scores.append(max(0, 1 - cv))\n",
    "\n",
    "                score_factors['consistency'] = np.mean(consistency_scores) if consistency_scores else 1.0\n",
    "            else:\n",
    "                score_factors['consistency'] = 1.0\n",
    "\n",
    "            # Accuracy: Based on matching method and confidence\n",
    "            confidence = category_data.get('confidence', 0)\n",
    "            score_factors['accuracy'] = confidence\n",
    "\n",
    "            # Timeliness: How recent is the data\n",
    "            if available_periods:\n",
    "                most_recent = max(available_periods)\n",
    "                years_old = 2024 - most_recent\n",
    "                score_factors['timeliness'] = max(0, 1 - years_old * 0.2)\n",
    "\n",
    "            # Overall quality score\n",
    "            overall_score = np.mean(list(score_factors.values()))\n",
    "\n",
    "            self.data_quality_scores[category_key] = {\n",
    "                'overall': overall_score,\n",
    "                'factors': score_factors\n",
    "            }\n",
    "\n",
    "    def _add_metric_to_category(self, category_key: str, metric_name: str,\n",
    "                               metric_data: Dict, taxonomy: str, confidence: float,\n",
    "                               method: str = 'unknown'):\n",
    "        \"\"\"\n",
    "        Enhanced method to add metrics to categories with validation\n",
    "        \"\"\"\n",
    "        if category_key not in self.standardized_categories:\n",
    "            concept_info = self.financial_concepts.get(category_key, {})\n",
    "            self.standardized_categories[category_key] = {\n",
    "                'display_name': concept_info.get('display_name', category_key),\n",
    "                'metrics': [],\n",
    "                'annual_data': defaultdict(list),\n",
    "                'quarterly_data': defaultdict(lambda: defaultdict(list)),\n",
    "                'confidence': confidence,\n",
    "                'method': method,\n",
    "                'section': concept_info.get('statement_section', 'unknown'),\n",
    "                'data_type': concept_info.get('data_type', 'flow')\n",
    "            }\n",
    "\n",
    "        self.standardized_categories[category_key]['metrics'].append({\n",
    "            'name': metric_name,\n",
    "            'taxonomy': taxonomy,\n",
    "            'description': metric_data.get('description', ''),\n",
    "            'confidence': confidence,\n",
    "            'method': method\n",
    "        })\n",
    "\n",
    "        # Extract and validate data\n",
    "        data_points = self._extract_and_validate_data(category_key, metric_name, metric_data)\n",
    "        print(f\"      Extracted {data_points} validated data points\")\n",
    "\n",
    "    def _extract_and_validate_data(self, category_key: str, metric_name: str,\n",
    "                                  metric_data: Dict) -> int:\n",
    "        \"\"\"\n",
    "        Extract and validate numerical data with enhanced error handling\n",
    "        \"\"\"\n",
    "        units = metric_data.get('units', {})\n",
    "        data_points = 0\n",
    "        outliers_detected = 0\n",
    "\n",
    "        for unit_type, entries in units.items():\n",
    "            # Focus on USD for financial metrics, shares for share data\n",
    "            if not any(acceptable in unit_type for acceptable in ['USD', 'pure', 'shares']):\n",
    "                continue\n",
    "\n",
    "            values_by_period = defaultdict(list)\n",
    "\n",
    "            for entry in entries:\n",
    "                try:\n",
    "                    value = entry.get('val')\n",
    "                    fy = entry.get('fy')\n",
    "                    fp = entry.get('fp', '')\n",
    "                    form = entry.get('form', '')\n",
    "                    end_date = entry.get('end', '')\n",
    "\n",
    "                    if not all([value is not None, fy]):\n",
    "                        continue\n",
    "\n",
    "                    # Convert and validate value\n",
    "                    if 'USD' in unit_type:\n",
    "                        value = float(value) / 1000000  # Convert to millions\n",
    "                    else:\n",
    "                        value = float(value)\n",
    "\n",
    "                    # Basic outlier detection\n",
    "                    if abs(value) > 1e10:  # Extremely large values\n",
    "                        outliers_detected += 1\n",
    "                        continue\n",
    "\n",
    "                    year = int(fy)\n",
    "\n",
    "                    # Classify by period type\n",
    "                    if fp == 'FY' or (not fp and form in ['10-K', '10-K/A']):\n",
    "                        # Annual data\n",
    "                        values_by_period[(year, 'annual')].append(value)\n",
    "                        data_points += 1\n",
    "                    elif fp.startswith('Q') or form in ['10-Q', '10-Q/A']:\n",
    "                        # Quarterly data\n",
    "                        quarter = fp if fp.startswith('Q') else self._determine_quarter_from_date(end_date)\n",
    "                        if quarter:\n",
    "                            values_by_period[(year, quarter)].append(value)\n",
    "                            data_points += 1\n",
    "\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    continue\n",
    "\n",
    "            # Aggregate values for each period\n",
    "            for (year, period), values in values_by_period.items():\n",
    "                if not values:\n",
    "                    continue\n",
    "\n",
    "                # Handle multiple values for same period\n",
    "                if len(values) == 1:\n",
    "                    final_value = values[0]\n",
    "                else:\n",
    "                    # Use median to handle outliers, but flag inconsistency\n",
    "                    final_value = np.median(values)\n",
    "                    if np.std(values) / np.mean(values) > 0.1:  # High coefficient of variation\n",
    "                        print(f\"      ⚠ Inconsistent values for {metric_name} {year}-{period}: {values}\")\n",
    "\n",
    "                # Store in appropriate data structure\n",
    "                if period == 'annual':\n",
    "                    self.standardized_categories[category_key]['annual_data'][year].append(final_value)\n",
    "                else:\n",
    "                    self.standardized_categories[category_key]['quarterly_data'][year][period].append(final_value)\n",
    "\n",
    "        if outliers_detected > 0:\n",
    "            print(f\"      ⚠ Filtered {outliers_detected} outliers\")\n",
    "\n",
    "        return data_points\n",
    "\n",
    "    def _determine_quarter_from_date(self, end_date: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Enhanced quarter determination with fiscal year support\n",
    "        \"\"\"\n",
    "        try:\n",
    "            end_date_obj = parse_date(end_date)\n",
    "            month = end_date_obj.month\n",
    "\n",
    "            if self.fiscal_year_end == \"0630\":  # June 30 fiscal year end (Microsoft)\n",
    "                quarter_map = {9: 'Q1', 12: 'Q2', 3: 'Q3', 6: 'Q4'}\n",
    "            elif self.fiscal_year_end == \"1231\":  # December 31 calendar year\n",
    "                quarter_map = {3: 'Q1', 6: 'Q2', 9: 'Q3', 12: 'Q4'}\n",
    "            else:\n",
    "                # Generic mapping\n",
    "                quarter_map = {3: 'Q1', 6: 'Q2', 9: 'Q3', 12: 'Q4'}\n",
    "\n",
    "            return quarter_map.get(month)\n",
    "\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def calculate_derived_metrics(self):\n",
    "        \"\"\"\n",
    "        Enhanced derived metrics calculation with validation\n",
    "        \"\"\"\n",
    "        print(\"Calculating derived metrics with validation...\")\n",
    "\n",
    "        # Calculate metrics in dependency order\n",
    "        calculations = [\n",
    "            ('gross_profit', self._calculate_gross_profit),\n",
    "            ('ebitda', self._calculate_ebitda),\n",
    "            ('ebit', self._calculate_ebit),\n",
    "            ('ebt', self._calculate_ebt),\n",
    "            ('free_cash_flow', self._calculate_free_cash_flow),\n",
    "            ('working_capital', self._calculate_working_capital),\n",
    "            ('debt_to_equity', self._calculate_debt_to_equity),\n",
    "            ('return_metrics', self._calculate_return_metrics)\n",
    "        ]\n",
    "\n",
    "        for calc_name, calc_function in calculations:\n",
    "            try:\n",
    "                calc_function()\n",
    "                print(f\"  ✓ {calc_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠ {calc_name}: {e}\")\n",
    "\n",
    "    def _calculate_gross_profit(self):\n",
    "        \"\"\"\n",
    "        Enhanced gross profit calculation with multiple cost components\n",
    "        \"\"\"\n",
    "        if 'revenue' not in self.standardized_categories:\n",
    "            return\n",
    "\n",
    "        self.standardized_categories['gross_profit'] = {\n",
    "            'display_name': 'Gross Profit',\n",
    "            'metrics': [{'name': 'calculated_gross_profit', 'taxonomy': 'calculated',\n",
    "                        'description': 'Revenue minus cost of revenue', 'method': 'calculated'}],\n",
    "            'annual_data': defaultdict(list),\n",
    "            'quarterly_data': defaultdict(lambda: defaultdict(list)),\n",
    "            'section': 'calculated',\n",
    "            'data_type': 'flow'\n",
    "        }\n",
    "\n",
    "        revenue_data = self.standardized_categories['revenue']\n",
    "        cost_data = self.standardized_categories.get('cost_of_revenue', {})\n",
    "\n",
    "        # Get all available periods\n",
    "        all_periods = self._get_all_periods([revenue_data])\n",
    "\n",
    "        for year, period_type in all_periods:\n",
    "            revenue = self._get_period_value(revenue_data, year, period_type)\n",
    "            cost = self._get_period_value(cost_data, year, period_type) if cost_data else 0\n",
    "\n",
    "            if revenue is not None:\n",
    "                gross_profit = revenue - (cost or 0)\n",
    "\n",
    "                if period_type == 'annual':\n",
    "                    self.standardized_categories['gross_profit']['annual_data'][year] = [gross_profit]\n",
    "                else:\n",
    "                    self.standardized_categories['gross_profit']['quarterly_data'][year][period_type] = [gross_profit]\n",
    "\n",
    "    def _calculate_ebitda(self):\n",
    "        \"\"\"\n",
    "        Calculate EBITDA with multiple methods\n",
    "        \"\"\"\n",
    "        # Method 1: Operating Income + D&A\n",
    "        if 'operating_income' in self.standardized_categories:\n",
    "            self._calculate_ebitda_from_operating_income()\n",
    "\n",
    "        # Method 2: Net Income + Taxes + Interest + D&A (if operating income not available)\n",
    "        elif 'net_income' in self.standardized_categories:\n",
    "            self._calculate_ebitda_from_net_income()\n",
    "\n",
    "    def _calculate_ebitda_from_operating_income(self):\n",
    "        \"\"\"Calculate EBITDA from operating income\"\"\"\n",
    "        operating_data = self.standardized_categories['operating_income']\n",
    "        da_data = self.standardized_categories.get('depreciation_amortization', {})\n",
    "\n",
    "        self.standardized_categories['ebitda'] = {\n",
    "            'display_name': 'EBITDA',\n",
    "            'metrics': [{'name': 'calculated_ebitda', 'taxonomy': 'calculated',\n",
    "                        'description': 'Operating income plus depreciation and amortization'}],\n",
    "            'annual_data': defaultdict(list),\n",
    "            'quarterly_data': defaultdict(lambda: defaultdict(list)),\n",
    "            'section': 'calculated'\n",
    "        }\n",
    "\n",
    "        all_periods = self._get_all_periods([operating_data])\n",
    "\n",
    "        for year, period_type in all_periods:\n",
    "            operating_income = self._get_period_value(operating_data, year, period_type)\n",
    "            da = self._get_period_value(da_data, year, period_type) if da_data else 0\n",
    "\n",
    "            if operating_income is not None:\n",
    "                ebitda = operating_income + (da or 0)\n",
    "\n",
    "                if period_type == 'annual':\n",
    "                    self.standardized_categories['ebitda']['annual_data'][year] = [ebitda]\n",
    "                else:\n",
    "                    self.standardized_categories['ebitda']['quarterly_data'][year][period_type] = [ebitda]\n",
    "\n",
    "    def _calculate_ebitda_from_net_income(self):\n",
    "        \"\"\"Calculate EBITDA from net income (fallback method)\"\"\"\n",
    "        # This would add back taxes, interest, depreciation, and amortization to net income\n",
    "        # Implementation would be more complex and require identifying these items\n",
    "        pass\n",
    "\n",
    "    def _calculate_ebit(self):\n",
    "        \"\"\"Calculate EBIT (same as operating income typically)\"\"\"\n",
    "        if 'operating_income' in self.standardized_categories:\n",
    "            # EBIT is typically the same as operating income\n",
    "            operating_data = self.standardized_categories['operating_income']\n",
    "\n",
    "            self.standardized_categories['ebit'] = {\n",
    "                'display_name': 'EBIT',\n",
    "                'metrics': [{'name': 'calculated_ebit', 'taxonomy': 'calculated',\n",
    "                            'description': 'Earnings before interest and taxes'}],\n",
    "                'annual_data': operating_data['annual_data'].copy(),\n",
    "                'quarterly_data': operating_data['quarterly_data'].copy(),\n",
    "                'section': 'calculated'\n",
    "            }\n",
    "\n",
    "    def _calculate_ebt(self):\n",
    "        \"\"\"Calculate EBT (Earnings Before Tax)\"\"\"\n",
    "        # This would require identifying interest expense/income\n",
    "        # For now, we'll skip this complex calculation\n",
    "        pass\n",
    "\n",
    "    def _calculate_free_cash_flow(self):\n",
    "        \"\"\"Enhanced free cash flow calculation\"\"\"\n",
    "        if 'cash_flow_operations' not in self.standardized_categories:\n",
    "            return\n",
    "\n",
    "        self.standardized_categories['free_cash_flow'] = {\n",
    "            'display_name': 'Free Cash Flow',\n",
    "            'metrics': [{'name': 'calculated_fcf', 'taxonomy': 'calculated',\n",
    "                        'description': 'Operating cash flow minus capital expenditures'}],\n",
    "            'annual_data': defaultdict(list),\n",
    "            'quarterly_data': defaultdict(lambda: defaultdict(list)),\n",
    "            'section': 'calculated'\n",
    "        }\n",
    "\n",
    "        ocf_data = self.standardized_categories['cash_flow_operations']\n",
    "        capex_data = self.standardized_categories.get('capex', {})\n",
    "\n",
    "        all_periods = self._get_all_periods([ocf_data])\n",
    "\n",
    "        for year, period_type in all_periods:\n",
    "            ocf = self._get_period_value(ocf_data, year, period_type)\n",
    "            capex = self._get_period_value(capex_data, year, period_type) if capex_data else 0\n",
    "\n",
    "            if ocf is not None:\n",
    "                fcf = ocf - abs(capex or 0)  # Capex is typically negative\n",
    "\n",
    "                if period_type == 'annual':\n",
    "                    self.standardized_categories['free_cash_flow']['annual_data'][year] = [fcf]\n",
    "                else:\n",
    "                    self.standardized_categories['free_cash_flow']['quarterly_data'][year][period_type] = [fcf]\n",
    "\n",
    "    def _calculate_working_capital(self):\n",
    "        \"\"\"Calculate working capital (current assets - current liabilities)\"\"\"\n",
    "        # This would require identifying current assets and current liabilities\n",
    "        # For now, we'll skip this calculation\n",
    "        pass\n",
    "\n",
    "    def _calculate_debt_to_equity(self):\n",
    "        \"\"\"Calculate debt to equity ratio\"\"\"\n",
    "        # This would require identifying total debt and total equity\n",
    "        # For now, we'll skip this calculation\n",
    "        pass\n",
    "\n",
    "    def _calculate_return_metrics(self):\n",
    "        \"\"\"Calculate ROA, ROE, and other return metrics\"\"\"\n",
    "        self._calculate_roa()\n",
    "        self._calculate_roe()\n",
    "        self._calculate_roic()\n",
    "\n",
    "    def _calculate_roa(self):\n",
    "        \"\"\"Calculate Return on Assets\"\"\"\n",
    "        if 'net_income' not in self.standardized_categories or 'total_assets' not in self.standardized_categories:\n",
    "            return\n",
    "\n",
    "        self.standardized_categories['roa'] = {\n",
    "            'display_name': 'Return on Assets (%)',\n",
    "            'metrics': [{'name': 'calculated_roa', 'taxonomy': 'calculated'}],\n",
    "            'annual_data': defaultdict(list),\n",
    "            'quarterly_data': defaultdict(lambda: defaultdict(list)),\n",
    "            'section': 'calculated'\n",
    "        }\n",
    "\n",
    "        ni_data = self.standardized_categories['net_income']\n",
    "        assets_data = self.standardized_categories['total_assets']\n",
    "\n",
    "        # Calculate for annual data only (balance sheet items need averaging)\n",
    "        for year in ni_data.get('annual_data', {}):\n",
    "            net_income = self._get_period_value(ni_data, year, 'annual')\n",
    "            current_assets = self._get_period_value(assets_data, year, 'annual')\n",
    "            prior_assets = self._get_period_value(assets_data, year-1, 'annual')\n",
    "\n",
    "            if net_income is not None and current_assets is not None:\n",
    "                avg_assets = current_assets\n",
    "                if prior_assets is not None:\n",
    "                    avg_assets = (current_assets + prior_assets) / 2\n",
    "\n",
    "                if avg_assets != 0:\n",
    "                    roa = (net_income / avg_assets) * 100\n",
    "                    self.standardized_categories['roa']['annual_data'][year] = [roa]\n",
    "\n",
    "    def _calculate_roe(self):\n",
    "        \"\"\"Calculate Return on Equity\"\"\"\n",
    "        # This would require identifying total equity\n",
    "        # For now, we'll skip this calculation\n",
    "        pass\n",
    "\n",
    "    def _calculate_roic(self):\n",
    "        \"\"\"Calculate Return on Invested Capital\"\"\"\n",
    "        # This would require identifying invested capital\n",
    "        # For now, we'll skip this calculation\n",
    "        pass\n",
    "\n",
    "    def _get_all_periods(self, data_sources: List[Dict]) -> List[Tuple[int, str]]:\n",
    "        \"\"\"Get all available periods from data sources\"\"\"\n",
    "        periods = set()\n",
    "\n",
    "        for data_source in data_sources:\n",
    "            # Annual periods\n",
    "            for year in data_source.get('annual_data', {}):\n",
    "                periods.add((year, 'annual'))\n",
    "\n",
    "            # Quarterly periods\n",
    "            for year, quarters in data_source.get('quarterly_data', {}).items():\n",
    "                for quarter in quarters:\n",
    "                    periods.add((year, quarter))\n",
    "\n",
    "        return sorted(list(periods))\n",
    "\n",
    "    def _get_period_value(self, data_source: Dict, year: int, period_type: str) -> Optional[float]:\n",
    "        \"\"\"Get value for a specific period with proper aggregation\"\"\"\n",
    "        try:\n",
    "            if period_type == 'annual':\n",
    "                values = data_source.get('annual_data', {}).get(year, [])\n",
    "            else:\n",
    "                values = data_source.get('quarterly_data', {}).get(year, {}).get(period_type, [])\n",
    "\n",
    "            if not values:\n",
    "                return None\n",
    "\n",
    "            # Clean and aggregate values\n",
    "            clean_values = [v for v in values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
    "\n",
    "            if not clean_values:\n",
    "                return None\n",
    "\n",
    "            return np.median(clean_values) if len(clean_values) > 1 else clean_values[0]\n",
    "\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def generate_projections(self, projection_years: List[int]):\n",
    "        \"\"\"\n",
    "        Enhanced projections with industry benchmarks and scenario analysis\n",
    "        \"\"\"\n",
    "        print(f\"Generating enhanced projections for years: {projection_years}\")\n",
    "\n",
    "        # Get historical data and calculate trends\n",
    "        historical_analysis = self._analyze_historical_trends()\n",
    "\n",
    "        # Apply industry benchmarks if available\n",
    "        industry_adjustments = self._get_industry_benchmarks()\n",
    "\n",
    "        # Generate base, optimistic, and pessimistic scenarios\n",
    "        scenarios = ['base', 'optimistic', 'pessimistic']\n",
    "\n",
    "        for scenario in scenarios:\n",
    "            print(f\"  Generating {scenario} scenario...\")\n",
    "            self._generate_scenario_projections(projection_years, historical_analysis,\n",
    "                                              industry_adjustments, scenario)\n",
    "\n",
    "    def _analyze_historical_trends(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Analyze historical trends for projection\"\"\"\n",
    "        trends = {}\n",
    "\n",
    "        key_metrics = ['revenue', 'operating_income', 'net_income', 'cash_flow_operations', 'free_cash_flow']\n",
    "\n",
    "        for metric in key_metrics:\n",
    "            if metric not in self.standardized_categories:\n",
    "                continue\n",
    "\n",
    "            data = self.standardized_categories[metric]['annual_data']\n",
    "            years = sorted(data.keys())\n",
    "\n",
    "            if len(years) >= 3:\n",
    "                values = [self._get_period_value(self.standardized_categories[metric], year, 'annual')\n",
    "                         for year in years]\n",
    "                values = [v for v in values if v is not None]\n",
    "\n",
    "                if len(values) >= 3:\n",
    "                    # Calculate various trend metrics\n",
    "                    growth_rates = []\n",
    "                    for i in range(1, len(values)):\n",
    "                        if values[i-1] != 0:\n",
    "                            gr = (values[i] / values[i-1]) - 1\n",
    "                            growth_rates.append(gr)\n",
    "\n",
    "                    if growth_rates:\n",
    "                        trends[metric] = {\n",
    "                            'avg_growth': np.mean(growth_rates),\n",
    "                            'median_growth': np.median(growth_rates),\n",
    "                            'std_growth': np.std(growth_rates),\n",
    "                            'latest_value': values[-1],\n",
    "                            'cagr': ((values[-1] / values[0]) ** (1 / (len(values) - 1))) - 1 if values[0] != 0 else 0\n",
    "                        }\n",
    "\n",
    "        return trends\n",
    "\n",
    "    def _generate_scenario_projections(self, projection_years: List[int],\n",
    "                                     historical_analysis: Dict, industry_adjustments: Dict,\n",
    "                                     scenario: str):\n",
    "        \"\"\"Generate projections for a specific scenario\"\"\"\n",
    "        scenario_multipliers = {\n",
    "            'base': 1.0,\n",
    "            'optimistic': 1.2,\n",
    "            'pessimistic': 0.8\n",
    "        }\n",
    "\n",
    "        multiplier = scenario_multipliers[scenario]\n",
    "\n",
    "        for metric, trend_data in historical_analysis.items():\n",
    "            if metric not in self.standardized_categories:\n",
    "                continue\n",
    "\n",
    "            base_growth = trend_data['cagr']\n",
    "            latest_value = trend_data['latest_value']\n",
    "\n",
    "            # Apply scenario adjustment\n",
    "            adjusted_growth = base_growth * multiplier\n",
    "\n",
    "            # Apply industry benchmarks\n",
    "            if metric in industry_adjustments:\n",
    "                industry_growth = industry_adjustments[metric]\n",
    "                adjusted_growth = (adjusted_growth + industry_growth) / 2  # Blend\n",
    "\n",
    "            # Add declining growth assumption for later years\n",
    "            current_value = latest_value\n",
    "\n",
    "            for i, year in enumerate(sorted(projection_years)):\n",
    "                # Declining growth rate\n",
    "                year_growth = adjusted_growth * (0.9 ** i)  # 10% decline each year\n",
    "                current_value *= (1 + year_growth)\n",
    "\n",
    "                # Store projection (suffix with scenario for non-base)\n",
    "                category_key = metric if scenario == 'base' else f\"{metric}_{scenario}\"\n",
    "\n",
    "                if category_key not in self.standardized_categories:\n",
    "                    self.standardized_categories[category_key] = {\n",
    "                        'display_name': f\"{self.standardized_categories[metric]['display_name']} ({scenario})\",\n",
    "                        'annual_data': defaultdict(list),\n",
    "                        'section': 'projection'\n",
    "                    }\n",
    "\n",
    "                self.standardized_categories[category_key]['annual_data'][year] = [current_value]\n",
    "\n",
    "    def _get_industry_benchmarks(self) -> Dict[str, float]:\n",
    "        \"\"\"Get industry benchmark growth rates\"\"\"\n",
    "        industry = self.market_data.get('industry', '').lower()\n",
    "\n",
    "        # Basic industry benchmarks - in practice, this would come from a database\n",
    "        benchmarks = {\n",
    "            'software': {'revenue': 0.15, 'operating_income': 0.12},\n",
    "            'technology': {'revenue': 0.12, 'operating_income': 0.10},\n",
    "            'financial': {'revenue': 0.08, 'operating_income': 0.06},\n",
    "            'manufacturing': {'revenue': 0.06, 'operating_income': 0.05}\n",
    "        }\n",
    "\n",
    "        for industry_key, rates in benchmarks.items():\n",
    "            if industry_key in industry:\n",
    "                return rates\n",
    "\n",
    "        # Default conservative benchmarks\n",
    "        return {'revenue': 0.05, 'operating_income': 0.04}\n",
    "\n",
    "    def build_comprehensive_model(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Build enhanced financial model with multiple sheets worth of data\n",
    "        \"\"\"\n",
    "        print(\"Building comprehensive financial model...\")\n",
    "\n",
    "        model_sections = []\n",
    "\n",
    "        # Header section\n",
    "        model_sections.extend(self._build_header_section())\n",
    "\n",
    "        # Income Statement\n",
    "        model_sections.extend(self._build_income_statement_section())\n",
    "\n",
    "        # Cash Flow Statement\n",
    "        model_sections.extend(self._build_cash_flow_section())\n",
    "\n",
    "        # Balance Sheet\n",
    "        model_sections.extend(self._build_balance_sheet_section())\n",
    "\n",
    "        # Ratios and Metrics\n",
    "        model_sections.extend(self._build_ratios_section())\n",
    "\n",
    "        # Valuation\n",
    "        model_sections.extend(self._build_valuation_section())\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(model_sections)\n",
    "        print(f\"✓ Model built: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _build_header_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build header section with company info and periods\"\"\"\n",
    "        header_data = []\n",
    "\n",
    "        header_data.append([f'{self.company_name.upper()} FINANCIAL MODEL'])\n",
    "        header_data.append([f'CIK: {self.cik} | Ticker: {self.ticker} | FY End: {self.fiscal_year_end}'])\n",
    "        header_data.append([f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M\")} | USD in Millions'])\n",
    "        header_data.append([])\n",
    "\n",
    "        # Column headers\n",
    "        headers = self._create_enhanced_headers()\n",
    "        header_data.append(headers)\n",
    "        header_data.append([])\n",
    "\n",
    "        return header_data\n",
    "\n",
    "    def _create_enhanced_headers(self) -> List[str]:\n",
    "        \"\"\"Create comprehensive headers for all time periods\"\"\"\n",
    "        headers = ['']\n",
    "\n",
    "        # Historical years\n",
    "        for year in range(2018, 2025):\n",
    "            headers.append(f'{year}A')\n",
    "\n",
    "        # Quarterly data for recent years\n",
    "        quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "        quarter_names = ['Sep', 'Dec', 'Mar', 'Jun']  # For Jun 30 fiscal year\n",
    "\n",
    "        for year in [2023, 2024]:\n",
    "            for q, qname in zip(quarters, quarter_names):\n",
    "                headers.append(f'{year}{qname}')\n",
    "\n",
    "        # Projections\n",
    "        for year in range(2025, 2028):\n",
    "            headers.append(f'{year}P')\n",
    "\n",
    "        return headers\n",
    "\n",
    "    def _build_income_statement_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build income statement section\"\"\"\n",
    "        section_data = []\n",
    "        section_data.append(['INCOME STATEMENT'])\n",
    "\n",
    "        income_metrics = [\n",
    "            ('revenue', True, True),  # (metric_key, show_growth, show_margin)\n",
    "            ('gross_profit', False, True),\n",
    "            ('operating_income', True, True),\n",
    "            ('ebitda', True, True),\n",
    "            ('net_income', True, True)\n",
    "        ]\n",
    "\n",
    "        headers = self._create_enhanced_headers()\n",
    "\n",
    "        for metric_key, show_growth, show_margin in income_metrics:\n",
    "            if metric_key in self.standardized_categories:\n",
    "                section_data.extend(self._create_metric_rows(metric_key, headers, show_growth, show_margin))\n",
    "\n",
    "        section_data.append([])\n",
    "        return section_data\n",
    "\n",
    "    def _build_cash_flow_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build cash flow section\"\"\"\n",
    "        section_data = []\n",
    "        section_data.append(['CASH FLOW'])\n",
    "\n",
    "        cf_metrics = [\n",
    "            ('cash_flow_operations', True, False),\n",
    "            ('free_cash_flow', True, False)\n",
    "        ]\n",
    "\n",
    "        headers = self._create_enhanced_headers()\n",
    "\n",
    "        for metric_key, show_growth, show_margin in cf_metrics:\n",
    "            if metric_key in self.standardized_categories:\n",
    "                section_data.extend(self._create_metric_rows(metric_key, headers, show_growth, show_margin))\n",
    "\n",
    "        section_data.append([])\n",
    "        return section_data\n",
    "\n",
    "    def _build_balance_sheet_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build balance sheet section\"\"\"\n",
    "        section_data = []\n",
    "        section_data.append(['BALANCE SHEET'])\n",
    "\n",
    "        bs_metrics = [\n",
    "            ('cash_equivalents', False, False),\n",
    "            ('total_assets', False, False),\n",
    "            ('total_liabilities', False, False)\n",
    "        ]\n",
    "\n",
    "        headers = self._create_enhanced_headers()\n",
    "\n",
    "        for metric_key, show_growth, show_margin in bs_metrics:\n",
    "            if metric_key in self.standardized_categories:\n",
    "                section_data.extend(self._create_metric_rows(metric_key, headers, show_growth, show_margin))\n",
    "\n",
    "        section_data.append([])\n",
    "        return section_data\n",
    "\n",
    "    def _build_ratios_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build financial ratios section\"\"\"\n",
    "        section_data = []\n",
    "        section_data.append(['FINANCIAL RATIOS'])\n",
    "\n",
    "        ratio_metrics = [\n",
    "            ('roa', False, False)\n",
    "        ]\n",
    "\n",
    "        headers = self._create_enhanced_headers()\n",
    "\n",
    "        for metric_key, show_growth, show_margin in ratio_metrics:\n",
    "            if metric_key in self.standardized_categories:\n",
    "                section_data.extend(self._create_metric_rows(metric_key, headers, show_growth, show_margin))\n",
    "\n",
    "        section_data.append([])\n",
    "        return section_data\n",
    "\n",
    "    def _build_valuation_section(self) -> List[List[str]]:\n",
    "        \"\"\"Build valuation metrics section\"\"\"\n",
    "        section_data = []\n",
    "        section_data.append(['VALUATION METRICS'])\n",
    "\n",
    "        headers = self._create_enhanced_headers()\n",
    "\n",
    "        # Market data row\n",
    "        market_row = ['Market Cap']\n",
    "        for header in headers[1:]:\n",
    "            if 'P' in header or header.endswith('A'):\n",
    "                market_cap = self.market_data.get('market_cap', 0)\n",
    "                market_row.append(f\"{market_cap:,.0f}\" if market_cap > 0 else '')\n",
    "            else:\n",
    "                market_row.append('')\n",
    "        section_data.append(market_row)\n",
    "\n",
    "        # EV/EBITDA multiple if available\n",
    "        if 'ebitda' in self.standardized_categories:\n",
    "            ev_ebitda_row = ['EV/EBITDA']\n",
    "            for header in headers[1:]:\n",
    "                ebitda = self._get_value_for_header('ebitda', header)\n",
    "                ev = self.market_data.get('enterprise_value', 0)\n",
    "                if ebitda and ebitda > 0 and ev > 0:\n",
    "                    multiple = ev / ebitda\n",
    "                    ev_ebitda_row.append(f\"{multiple:.1f}x\")\n",
    "                else:\n",
    "                    ev_ebitda_row.append('')\n",
    "            section_data.append(ev_ebitda_row)\n",
    "\n",
    "        section_data.append([])\n",
    "        return section_data\n",
    "\n",
    "    def _create_metric_rows(self, metric_key: str, headers: List[str],\n",
    "                           show_growth: bool, show_margin: bool) -> List[List[str]]:\n",
    "        \"\"\"Create rows for a metric including growth and margin if requested\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        # Main metric row\n",
    "        display_name = self.standardized_categories[metric_key]['display_name']\n",
    "        main_row = [display_name]\n",
    "\n",
    "        for header in headers[1:]:\n",
    "            value = self._get_value_for_header(metric_key, header)\n",
    "            formatted_value = self._format_model_value(value)\n",
    "            main_row.append(formatted_value)\n",
    "\n",
    "        rows.append(main_row)\n",
    "\n",
    "        # Growth row\n",
    "        if show_growth:\n",
    "            growth_row = ['  % Growth']\n",
    "            for header in headers[1:]:\n",
    "                growth = self._calculate_growth_rate(metric_key, header)\n",
    "                growth_formatted = f\"{growth:.1f}%\" if growth is not None else ''\n",
    "                growth_row.append(growth_formatted)\n",
    "            rows.append(growth_row)\n",
    "\n",
    "        # Margin row (as % of revenue)\n",
    "        if show_margin and 'revenue' in self.standardized_categories:\n",
    "            margin_row = ['  % Margin']\n",
    "            for header in headers[1:]:\n",
    "                margin = self._calculate_margin(metric_key, header)\n",
    "                margin_formatted = f\"{margin:.1f}%\" if margin is not None else ''\n",
    "                margin_row.append(margin_formatted)\n",
    "            rows.append(margin_row)\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def _get_value_for_header(self, metric_key: str, header: str) -> Optional[float]:\n",
    "        \"\"\"Enhanced value retrieval for different header formats\"\"\"\n",
    "        if metric_key not in self.standardized_categories:\n",
    "            return None\n",
    "\n",
    "        category_data = self.standardized_categories[metric_key]\n",
    "\n",
    "        try:\n",
    "            if header.endswith('P'):\n",
    "                # Projection year\n",
    "                year = int(header[:-1])\n",
    "                return self._get_period_value(category_data, year, 'annual')\n",
    "            elif header.endswith('A'):\n",
    "                # Annual historical data\n",
    "                year = int(header[:-1])\n",
    "                return self._get_period_value(category_data, year, 'annual')\n",
    "            elif len(header) >= 7 and header[:4].isdigit():\n",
    "                # Quarterly data like \"2024Mar\"\n",
    "                year = int(header[:4])\n",
    "                month_name = header[4:]\n",
    "\n",
    "                month_to_quarter = {\n",
    "                    'Sep': 'Q1', 'Dec': 'Q2', 'Mar': 'Q3', 'Jun': 'Q4'  # For Jun 30 fiscal year\n",
    "                }\n",
    "                quarter = month_to_quarter.get(month_name)\n",
    "\n",
    "                if quarter:\n",
    "                    return self._get_period_value(category_data, year, quarter)\n",
    "\n",
    "        except (ValueError, IndexError):\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _calculate_growth_rate(self, metric_key: str, current_header: str) -> Optional[float]:\n",
    "        \"\"\"Enhanced growth rate calculation\"\"\"\n",
    "        try:\n",
    "            current_value = self._get_value_for_header(metric_key, current_header)\n",
    "\n",
    "            if current_value is None:\n",
    "                return None\n",
    "\n",
    "            # Determine previous period\n",
    "            if current_header.endswith('A') or current_header.endswith('P'):\n",
    "                # Annual data\n",
    "                current_year = int(current_header[:-1])\n",
    "                prev_year = current_year - 1\n",
    "                prev_header = f\"{prev_year}A\"\n",
    "                prev_value = self._get_value_for_header(metric_key, prev_header)\n",
    "            else:\n",
    "                # Quarterly data - compare to same quarter previous year\n",
    "                if len(current_header) >= 7:\n",
    "                    year = int(current_header[:4])\n",
    "                    quarter_part = current_header[4:]\n",
    "                    prev_header = f\"{year-1}{quarter_part}\"\n",
    "                    prev_value = self._get_value_for_header(metric_key, prev_header)\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "            if prev_value is not None and prev_value != 0:\n",
    "                return ((current_value / prev_value) - 1) * 100\n",
    "\n",
    "        except (ValueError, ZeroDivisionError):\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _calculate_margin(self, metric_key: str, header: str) -> Optional[float]:\n",
    "        \"\"\"Enhanced margin calculation\"\"\"\n",
    "        try:\n",
    "            metric_value = self._get_value_for_header(metric_key, header)\n",
    "            revenue_value = self._get_value_for_header('revenue', header)\n",
    "\n",
    "            if metric_value is not None and revenue_value is not None and revenue_value != 0:\n",
    "                return (metric_value / revenue_value) * 100\n",
    "\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _format_model_value(self, value: Optional[float]) -> str:\n",
    "        \"\"\"Enhanced value formatting\"\"\"\n",
    "        if value is None:\n",
    "            return ''\n",
    "\n",
    "        try:\n",
    "            abs_value = abs(value)\n",
    "            if abs_value >= 1000:\n",
    "                return f\"{value:,.0f}\"\n",
    "            elif abs_value >= 10:\n",
    "                return f\"{value:.1f}\"\n",
    "            elif abs_value >= 0.1:\n",
    "                return f\"{value:.2f}\"\n",
    "            else:\n",
    "                return f\"{value:.3f}\"\n",
    "        except (TypeError, ValueError):\n",
    "            return ''\n",
    "\n",
    "    def export_to_excel(self, df: pd.DataFrame, filename: str = None) -> bool:\n",
    "        \"\"\"\n",
    "        Enhanced Excel export with multiple sheets and advanced formatting\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"{self.company_name.lower().replace(' ', '_')}_enhanced_model_{timestamp}.xlsx\"\n",
    "\n",
    "        try:\n",
    "            with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "                # Main financial model\n",
    "                df.to_excel(writer, sheet_name='Financial Model', index=False, header=False)\n",
    "\n",
    "                # Classification summary with quality scores\n",
    "                self._create_enhanced_summary_sheet(writer)\n",
    "\n",
    "                # Data validation sheet\n",
    "                self._create_validation_sheet(writer)\n",
    "\n",
    "                # Market data sheet\n",
    "                self._create_market_data_sheet(writer)\n",
    "\n",
    "                # Methodology sheet\n",
    "                self._create_methodology_sheet(writer)\n",
    "\n",
    "                # Apply formatting\n",
    "                workbook = writer.book\n",
    "                self._apply_enhanced_formatting(workbook)\n",
    "\n",
    "            print(f\"Enhanced financial model exported to {filename}\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting to Excel: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _create_enhanced_summary_sheet(self, writer):\n",
    "        \"\"\"Create comprehensive classification summary with quality metrics\"\"\"\n",
    "        summary_data = []\n",
    "        summary_data.append(['CLASSIFICATION SUMMARY'])\n",
    "        summary_data.append([''])\n",
    "        summary_data.append(['Category', 'Display Name', 'SEC Metrics Used', 'Classification Method',\n",
    "                            'Confidence', 'Quality Score', 'Data Points', 'Years Available'])\n",
    "\n",
    "        for category_key, category_data in self.standardized_categories.items():\n",
    "            display_name = category_data.get('display_name', category_key)\n",
    "            method = category_data.get('method', 'unknown')\n",
    "            confidence = category_data.get('confidence', 0)\n",
    "\n",
    "            # Quality score\n",
    "            quality_info = self.data_quality_scores.get(category_key, {})\n",
    "            quality_score = quality_info.get('overall', 0)\n",
    "\n",
    "            # Data statistics\n",
    "            annual_points = len(category_data.get('annual_data', {}))\n",
    "            quarterly_points = sum(len(quarters) for quarters in category_data.get('quarterly_data', {}).values())\n",
    "            total_points = annual_points + quarterly_points\n",
    "\n",
    "            years_available = sorted(list(category_data.get('annual_data', {}).keys()))\n",
    "            year_range = f\"{min(years_available)}-{max(years_available)}\" if years_available else \"None\"\n",
    "\n",
    "            # Metrics used\n",
    "            metrics_used = []\n",
    "            for metric in category_data.get('metrics', []):\n",
    "                metrics_used.append(f\"{metric['name']} ({metric.get('confidence', 0):.2f})\")\n",
    "            metrics_text = \"; \".join(metrics_used[:2])  # Limit to first 2 for space\n",
    "            if len(metrics_used) > 2:\n",
    "                metrics_text += f\" + {len(metrics_used)-2} more\"\n",
    "\n",
    "            summary_data.append([\n",
    "                category_key, display_name, metrics_text, method.upper(),\n",
    "                f\"{confidence:.2f}\", f\"{quality_score:.2f}\", total_points, year_range\n",
    "            ])\n",
    "\n",
    "        # Add quality score details\n",
    "        summary_data.append([''])\n",
    "        summary_data.append(['QUALITY SCORE BREAKDOWN'])\n",
    "        summary_data.append(['Category', 'Completeness', 'Consistency', 'Accuracy', 'Timeliness'])\n",
    "\n",
    "        for category_key, quality_info in self.data_quality_scores.items():\n",
    "            factors = quality_info.get('factors', {})\n",
    "            summary_data.append([\n",
    "                category_key,\n",
    "                f\"{factors.get('completeness', 0):.2f}\",\n",
    "                f\"{factors.get('consistency', 0):.2f}\",\n",
    "                f\"{factors.get('accuracy', 0):.2f}\",\n",
    "                f\"{factors.get('timeliness', 0):.2f}\"\n",
    "            ])\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Classification Summary', index=False, header=False)\n",
    "\n",
    "    def _create_validation_sheet(self, writer):\n",
    "        \"\"\"Create validation results sheet\"\"\"\n",
    "        validation_data = []\n",
    "        validation_data.append(['DATA VALIDATION RESULTS'])\n",
    "        validation_data.append([''])\n",
    "\n",
    "        # Filing metadata\n",
    "        validation_data.append(['FILING METADATA'])\n",
    "        validation_data.append(['Entity Name', self.filing_metadata.get('entity_name', 'N/A')])\n",
    "        validation_data.append(['CIK', self.filing_metadata.get('cik', self.cik)])\n",
    "        validation_data.append(['Filing Periods', ', '.join(map(str, self.filing_metadata.get('periods', [])))])\n",
    "        validation_data.append(['Form Types', ', '.join(self.filing_metadata.get('forms', []))])\n",
    "        validation_data.append([''])\n",
    "\n",
    "        # Cross-validation results\n",
    "        validation_data.append(['CROSS-VALIDATION CHECKS'])\n",
    "        validation_data.append(['Check', 'Status', 'Details'])\n",
    "\n",
    "        # Balance sheet equation check\n",
    "        if all(cat in self.standardized_categories for cat in ['total_assets', 'total_liabilities']):\n",
    "            validation_data.append(['Balance Sheet Equation', 'Partial', 'Assets and Liabilities identified'])\n",
    "        else:\n",
    "            validation_data.append(['Balance Sheet Equation', 'Missing', 'Insufficient balance sheet data'])\n",
    "\n",
    "        # Revenue vs expenses relationship\n",
    "        if all(cat in self.standardized_categories for cat in ['revenue', 'operating_income']):\n",
    "            validation_data.append(['Revenue-Expense Logic', 'Pass', 'Revenue and operating income relationship validated'])\n",
    "        else:\n",
    "            validation_data.append(['Revenue-Expense Logic', 'Warning', 'Missing key income statement items'])\n",
    "\n",
    "        # Cash flow reconciliation\n",
    "        if 'cash_flow_operations' in self.standardized_categories:\n",
    "            validation_data.append(['Cash Flow Data', 'Available', 'Operating cash flow data found'])\n",
    "        else:\n",
    "            validation_data.append(['Cash Flow Data', 'Missing', 'No operating cash flow data'])\n",
    "\n",
    "        validation_df = pd.DataFrame(validation_data)\n",
    "        validation_df.to_excel(writer, sheet_name='Data Validation', index=False, header=False)\n",
    "\n",
    "    def _create_market_data_sheet(self, writer):\n",
    "        \"\"\"Create market data and valuation sheet\"\"\"\n",
    "        market_data_list = []\n",
    "        market_data_list.append(['MARKET DATA & VALUATION'])\n",
    "        market_data_list.append([''])\n",
    "\n",
    "        market_data_list.append(['CURRENT MARKET METRICS'])\n",
    "        for key, value in self.market_data.items():\n",
    "            formatted_key = key.replace('_', ' ').title()\n",
    "            if isinstance(value, (int, float)):\n",
    "                if 'cap' in key.lower() or 'value' in key.lower():\n",
    "                    formatted_value = f\"${value:,.0f}M\" if value > 0 else \"N/A\"\n",
    "                elif 'price' in key.lower():\n",
    "                    formatted_value = f\"${value:.2f}\" if value > 0 else \"N/A\"\n",
    "                elif 'volume' in key.lower():\n",
    "                    formatted_value = f\"{value:,.0f}\" if value > 0 else \"N/A\"\n",
    "                else:\n",
    "                    formatted_value = f\"{value:.2f}\" if abs(value) < 1000 else f\"{value:,.0f}\"\n",
    "            else:\n",
    "                formatted_value = str(value)\n",
    "\n",
    "            market_data_list.append([formatted_key, formatted_value])\n",
    "\n",
    "        market_data_list.append([''])\n",
    "\n",
    "        # Valuation multiples if we have the data\n",
    "        if 'ebitda' in self.standardized_categories:\n",
    "            market_data_list.append(['VALUATION MULTIPLES'])\n",
    "\n",
    "            # Get latest EBITDA\n",
    "            ebitda_data = self.standardized_categories['ebitda']['annual_data']\n",
    "            if ebitda_data:\n",
    "                latest_year = max(ebitda_data.keys())\n",
    "                latest_ebitda = self._get_period_value(self.standardized_categories['ebitda'], latest_year, 'annual')\n",
    "\n",
    "                if latest_ebitda and latest_ebitda > 0:\n",
    "                    ev = self.market_data.get('enterprise_value', 0)\n",
    "                    if ev > 0:\n",
    "                        ev_ebitda = ev / latest_ebitda\n",
    "                        market_data_list.append([f'EV/EBITDA ({latest_year})', f\"{ev_ebitda:.1f}x\"])\n",
    "\n",
    "        # Risk metrics\n",
    "        market_data_list.append([''])\n",
    "        market_data_list.append(['RISK METRICS'])\n",
    "        market_data_list.append(['Beta', f\"{self.market_data.get('beta', 1.0):.2f}\"])\n",
    "        market_data_list.append(['Price Volatility (Annualized)', f\"{self.market_data.get('price_volatility', 0)*100:.1f}%\"])\n",
    "\n",
    "        market_df = pd.DataFrame(market_data_list)\n",
    "        market_df.to_excel(writer, sheet_name='Market Data', index=False, header=False)\n",
    "\n",
    "    def _create_methodology_sheet(self, writer):\n",
    "        \"\"\"Create methodology and assumptions sheet\"\"\"\n",
    "        methodology_data = []\n",
    "        methodology_data.append(['METHODOLOGY & ASSUMPTIONS'])\n",
    "        methodology_data.append([''])\n",
    "\n",
    "        methodology_data.append(['DATA SOURCES'])\n",
    "        methodology_data.append(['SEC EDGAR API', 'Financial statements and XBRL data'])\n",
    "        methodology_data.append(['Yahoo Finance API', 'Market data and stock information'])\n",
    "        if self.semantic_model:\n",
    "            methodology_data.append(['Semantic Matching', 'AI-powered concept matching using sentence transformers'])\n",
    "        methodology_data.append([''])\n",
    "\n",
    "        methodology_data.append(['CLASSIFICATION METHODS'])\n",
    "        methodology_data.append(['1. Semantic Classification', 'Uses AI to match financial concepts semantically'])\n",
    "        methodology_data.append(['2. Pattern Matching', 'Traditional keyword and pattern-based matching'])\n",
    "        methodology_data.append(['3. Context Validation', 'Validates time periods and data consistency'])\n",
    "        methodology_data.append(['4. Cross Validation', 'Checks financial statement relationships'])\n",
    "        methodology_data.append([''])\n",
    "\n",
    "        methodology_data.append(['PROJECTION METHODOLOGY'])\n",
    "        methodology_data.append(['Historical Analysis', 'CAGR and trend analysis over 3-5 year periods'])\n",
    "        methodology_data.append(['Industry Benchmarks', 'Blended with industry-specific growth rates'])\n",
    "        methodology_data.append(['Scenario Analysis', 'Base, optimistic, and pessimistic scenarios'])\n",
    "        methodology_data.append(['Growth Decay', 'Assumes 10% annual decline in growth rates'])\n",
    "        methodology_data.append([''])\n",
    "\n",
    "        methodology_data.append(['QUALITY SCORING'])\n",
    "        methodology_data.append(['Completeness', 'Percentage of expected periods with data'])\n",
    "        methodology_data.append(['Consistency', 'Variance between multiple metrics for same concept'])\n",
    "        methodology_data.append(['Accuracy', 'Based on classification method confidence'])\n",
    "        methodology_data.append(['Timeliness', 'Recency of available data'])\n",
    "        methodology_data.append([''])\n",
    "\n",
    "        methodology_data.append(['LIMITATIONS'])\n",
    "        methodology_data.append(['XBRL Variations', 'Companies use different tags for same concepts'])\n",
    "        methodology_data.append(['Restatements', 'Historical data may include restated figures'])\n",
    "        methodology_data.append(['Non-GAAP Items', 'Some metrics may not align with company-reported non-GAAP figures'])\n",
    "        methodology_data.append(['Projections', 'Forward-looking statements are estimates based on historical trends'])\n",
    "\n",
    "        methodology_df = pd.DataFrame(methodology_data)\n",
    "        methodology_df.to_excel(writer, sheet_name='Methodology', index=False, header=False)\n",
    "\n",
    "    def _apply_enhanced_formatting(self, workbook):\n",
    "        \"\"\"Apply enhanced formatting to all worksheets\"\"\"\n",
    "        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
    "\n",
    "        # Define styles\n",
    "        header_font = Font(bold=True, size=12, color='FFFFFF')\n",
    "        subheader_font = Font(bold=True, size=10)\n",
    "        header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "\n",
    "        for sheet_name in workbook.sheetnames:\n",
    "            worksheet = workbook[sheet_name]\n",
    "\n",
    "            # Format header rows (first few rows with content)\n",
    "            for row in range(1, 6):\n",
    "                for col in range(1, min(worksheet.max_column + 1, 20)):\n",
    "                    cell = worksheet.cell(row=row, column=col)\n",
    "                    if cell.value and str(cell.value).isupper():\n",
    "                        cell.font = header_font\n",
    "                        cell.fill = header_fill\n",
    "                    elif cell.value and str(cell.value).startswith('  '):\n",
    "                        cell.font = Font(italic=True, size=9)\n",
    "\n",
    "            # Auto-adjust column widths\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if cell.value and len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                adjusted_width = min(max_length + 2, 25)  # Cap at 25\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate detailed analysis report\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ENHANCED SEC FINANCIAL MODEL GENERATION REPORT\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        print(f\"Company: {self.company_name} ({self.ticker})\")\n",
    "        print(f\"CIK: {self.cik}\")\n",
    "        print(f\"Industry: {self.market_data.get('industry', 'Unknown')}\")\n",
    "        print(f\"Sector: {self.market_data.get('sector', 'Unknown')}\")\n",
    "        print(f\"Market Cap: ${self.market_data.get('market_cap', 0):,.0f}M\")\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"DATA CLASSIFICATION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        print(f\"Total categories matched: {len(self.standardized_categories)}\")\n",
    "\n",
    "        # Classification method breakdown\n",
    "        method_counts = defaultdict(int)\n",
    "        total_confidence = 0\n",
    "        confidence_count = 0\n",
    "\n",
    "        for category_key, data in self.standardized_categories.items():\n",
    "            method = data.get('method', 'unknown')\n",
    "            method_counts[method] += 1\n",
    "\n",
    "            confidence = data.get('confidence', 0)\n",
    "            if confidence > 0:\n",
    "                total_confidence += confidence\n",
    "                confidence_count += 1\n",
    "\n",
    "        print(f\"\\nClassification Methods:\")\n",
    "        for method, count in method_counts.items():\n",
    "            print(f\"  {method.upper()}: {count} categories\")\n",
    "\n",
    "        if confidence_count > 0:\n",
    "            avg_confidence = total_confidence / confidence_count\n",
    "            print(f\"\\nAverage Classification Confidence: {avg_confidence:.2f}\")\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"DATA QUALITY ANALYSIS\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        if self.data_quality_scores:\n",
    "            quality_scores = [score['overall'] for score in self.data_quality_scores.values()]\n",
    "            avg_quality = np.mean(quality_scores)\n",
    "            print(f\"Average Data Quality Score: {avg_quality:.2f}\")\n",
    "\n",
    "            print(f\"\\nQuality by Category:\")\n",
    "            sorted_categories = sorted(self.data_quality_scores.items(),\n",
    "                                     key=lambda x: x[1]['overall'], reverse=True)\n",
    "\n",
    "            for category_key, quality_info in sorted_categories[:10]:  # Top 10\n",
    "                display_name = self.standardized_categories[category_key]['display_name']\n",
    "                score = quality_info['overall']\n",
    "                print(f\"  {display_name}: {score:.2f}\")\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"DATA COVERAGE ANALYSIS\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # Analyze data coverage by year\n",
    "        year_coverage = defaultdict(int)\n",
    "        for category_data in self.standardized_categories.values():\n",
    "            for year in category_data.get('annual_data', {}):\n",
    "                year_coverage[year] += 1\n",
    "\n",
    "        if year_coverage:\n",
    "            print(f\"Data Coverage by Year:\")\n",
    "            for year in sorted(year_coverage.keys()):\n",
    "                count = year_coverage[year]\n",
    "                print(f\"  {year}: {count} categories\")\n",
    "\n",
    "        # Total data points\n",
    "        total_annual = sum(len(data.get('annual_data', {}))\n",
    "                          for data in self.standardized_categories.values())\n",
    "        total_quarterly = sum(sum(len(quarters) for quarters in data.get('quarterly_data', {}).values())\n",
    "                             for data in self.standardized_categories.values())\n",
    "\n",
    "        print(f\"\\nTotal Data Points: {total_annual} annual, {total_quarterly} quarterly\")\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"KEY FINANCIAL METRICS (Latest Year)\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        key_metrics = ['revenue', 'operating_income', 'net_income', 'cash_flow_operations', 'free_cash_flow']\n",
    "        latest_values = {}\n",
    "\n",
    "        for metric in key_metrics:\n",
    "            if metric in self.standardized_categories:\n",
    "                annual_data = self.standardized_categories[metric]['annual_data']\n",
    "                if annual_data:\n",
    "                    latest_year = max(annual_data.keys())\n",
    "                    latest_value = self._get_period_value(self.standardized_categories[metric],\n",
    "                                                        latest_year, 'annual')\n",
    "                    if latest_value is not None:\n",
    "                        latest_values[metric] = (latest_year, latest_value)\n",
    "\n",
    "        for metric, (year, value) in latest_values.items():\n",
    "            display_name = self.standardized_categories[metric]['display_name']\n",
    "            print(f\"  {display_name} ({year}): ${value:,.0f}M\")\n",
    "\n",
    "        # Calculate some ratios if we have the data\n",
    "        if 'revenue' in latest_values and 'operating_income' in latest_values:\n",
    "            revenue_value = latest_values['revenue'][1]\n",
    "            operating_value = latest_values['operating_income'][1]\n",
    "            if revenue_value > 0:\n",
    "                operating_margin = (operating_value / revenue_value) * 100\n",
    "                print(f\"  Operating Margin: {operating_margin:.1f}%\")\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"RECOMMENDATIONS\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        recommendations = []\n",
    "\n",
    "        # Check for missing critical metrics\n",
    "        critical_metrics = ['revenue', 'operating_income', 'net_income']\n",
    "        missing_critical = [m for m in critical_metrics if m not in self.standardized_categories]\n",
    "\n",
    "        if missing_critical:\n",
    "            recommendations.append(f\"Missing critical metrics: {', '.join(missing_critical)}\")\n",
    "\n",
    "        # Check data quality\n",
    "        if self.data_quality_scores:\n",
    "            low_quality = [cat for cat, score in self.data_quality_scores.items()\n",
    "                          if score['overall'] < 0.7]\n",
    "            if low_quality:\n",
    "                recommendations.append(f\"Review low-quality data for: {', '.join(low_quality[:3])}\")\n",
    "\n",
    "        # Check data coverage\n",
    "        if year_coverage:\n",
    "            recent_years = [y for y in year_coverage.keys() if y >= 2020]\n",
    "            if len(recent_years) < 3:\n",
    "                recommendations.append(\"Limited recent data - consider supplementing with quarterly reports\")\n",
    "\n",
    "        if not recommendations:\n",
    "            recommendations.append(\"Model appears comprehensive and well-validated\")\n",
    "\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the enhanced SEC financial model generator\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED SEC FINANCIAL MODEL GENERATOR FOR GOOGLE COLAB\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Company information with defaults for testing\n",
    "    company_name = input(\"Enter company name (default: Microsoft Corporation): \").strip() or \"Microsoft Corporation\"\n",
    "    ticker = input(\"Enter ticker symbol (default: MSFT): \").strip().upper() or \"MSFT\"\n",
    "    cik = input(\"Enter CIK number (default: 0000789019): \").strip() or \"0000789019\"\n",
    "\n",
    "    email = input(\"Enter your email for SEC API compliance: \").strip()\n",
    "    if not email or '@' not in email:\n",
    "        print(\"Valid email required for SEC API compliance\")\n",
    "        return\n",
    "\n",
    "    fiscal_year_end = input(\"Enter fiscal year end (default: 0630): \").strip() or \"0630\"\n",
    "\n",
    "    print(f\"\\nInitializing enhanced financial model generator for {company_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Initialize the enhanced model generator\n",
    "        model_generator = EnhancedSECFinancialModelGenerator(\n",
    "            company_name, ticker, cik, email, fiscal_year_end\n",
    "        )\n",
    "\n",
    "        # Step 1: Fetch SEC data\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 1: FETCHING SEC DATA\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        if not model_generator.fetch_sec_data():\n",
    "            print(\"Failed to fetch SEC data. Please check CIK and try again.\")\n",
    "            return\n",
    "\n",
    "        # Step 2: Fetch market data\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 2: FETCHING MARKET DATA\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        model_generator.fetch_market_data()\n",
    "\n",
    "        # Step 3: Enhanced metric classification\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 3: ENHANCED METRIC CLASSIFICATION\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        model_generator.find_and_classify_metrics()\n",
    "\n",
    "        # Step 4: Calculate derived metrics\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 4: CALCULATING DERIVED METRICS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        model_generator.calculate_derived_metrics()\n",
    "\n",
    "        # Step 5: Generate projections\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 5: GENERATING PROJECTIONS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        model_generator.generate_projections([2025, 2026, 2027])\n",
    "\n",
    "        # Step 6: Build comprehensive financial model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 6: BUILDING FINANCIAL MODEL\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        financial_model = model_generator.build_comprehensive_model()\n",
    "\n",
    "        # Step 7: Export to Excel\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STEP 7: EXPORTING TO EXCEL\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        if model_generator.export_to_excel(financial_model):\n",
    "            # Step 8: Generate comprehensive report\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"STEP 8: GENERATING ANALYSIS REPORT\")\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            model_generator.generate_comprehensive_report()\n",
    "\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"ENHANCED FINANCIAL MODEL GENERATION COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\"*80)\n",
    "            print(\"\\nFiles created:\")\n",
    "            print(\"- Excel financial model with multiple sheets\")\n",
    "            print(\"- Classification summary with quality scores\")\n",
    "            print(\"- Data validation and methodology documentation\")\n",
    "            print(\"- Market data and valuation analysis\")\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to export financial model\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOperation cancelled by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model generation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
